import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.preprocessing import MinMaxScaler
import os
import joblib
import numpy as np

def load_and_prepare_data():
    """Verileri yÃ¼kle ve hazÄ±rla"""
    # Dosya yolu
    folder_path = r"D:\MasaÃ¼stÃ¼\EcoHalt Solar\GTFS"
    input_file = os.path.join(folder_path, "enhanced_solar_analysis.csv")
    
    # Veriyi oku
    df = pd.read_csv(input_file)
    
    # Etiket oluÅŸtur (en uygun %20 durak = 1, diÄŸerleri = 0)
    threshold = df['suitability_score'].quantile(0.80)
    df['label'] = (df['suitability_score'] >= threshold).astype(int)
    
    return df

def train_model(df):
    """Modeli eÄŸit ve deÄŸerlendir"""
    # GiriÅŸ deÄŸiÅŸkenleri (Ã¶zellikler)
    features = ['irradiation_kWh', 'passenger_density', 'metro_distance']
    X = df[features]
    y = df['label']
    
    # Normalize et
    scaler = MinMaxScaler()
    X_scaled = scaler.fit_transform(X)
    
    # EÄŸitim ve test setine ayÄ±r
    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y, test_size=0.2, random_state=42
    )
    
    # Random Forest Modeli
    model = RandomForestClassifier(
        n_estimators=100,
        max_depth=10,
        min_samples_split=5,
        min_samples_leaf=2,
        random_state=42
    )
    
    # Modeli eÄŸit
    model.fit(X_train, y_train)
    
    # Test seti Ã¼zerinde tahmin yap
    preds = model.predict(X_test)
    
    # SonuÃ§larÄ± yazdÄ±r
    print("\nğŸ” Classification Report:")
    print(classification_report(y_test, preds))
    
    print("\nğŸ“‰ Confusion Matrix:")
    print(confusion_matrix(y_test, preds))
    
    # Ã–zellik Ã¶nemliliklerini yazdÄ±r
    feature_importance = pd.DataFrame({
        'feature': features,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    print("\nğŸ“Š Ã–zellik Ã–nemlilikleri:")
    print(feature_importance)
    
    return model, scaler, features

def save_model(model, scaler, features):
    """Modeli ve scaler'Ä± kaydet"""
    folder_path = r"D:\MasaÃ¼stÃ¼\EcoHalt Solar\GTFS"
    
    # Modeli kaydet
    model_path = os.path.join(folder_path, "solar_stop_model.joblib")
    joblib.dump(model, model_path)
    
    # Scaler'Ä± kaydet
    scaler_path = os.path.join(folder_path, "solar_stop_scaler.joblib")
    joblib.dump(scaler, scaler_path)
    
    # Ã–zellik listesini kaydet
    features_path = os.path.join(folder_path, "model_features.txt")
    with open(features_path, 'w') as f:
        f.write('\n'.join(features))
    
    print(f"\nâœ… Model kaydedildi: {model_path}")
    print(f"âœ… Scaler kaydedildi: {scaler_path}")
    print(f"âœ… Ã–zellik listesi kaydedildi: {features_path}")

def predict_new_stops(model, scaler, features):
    """Yeni duraklar iÃ§in tahmin yap"""
    # Ã–rnek yeni duraklar
    new_stops = pd.DataFrame({
        'irradiation_kWh': [1200, 1100, 1300],
        'passenger_density': [80, 60, 90],
        'metro_distance': [500, 1000, 300]
    })
    
    # Verileri normalize et
    X_new = scaler.transform(new_stops[features])
    
    # Tahmin yap
    predictions = model.predict(X_new)
    probabilities = model.predict_proba(X_new)
    
    # SonuÃ§larÄ± yazdÄ±r
    print("\nğŸ”® Yeni Duraklar iÃ§in Tahminler:")
    for i, (pred, prob) in enumerate(zip(predictions, probabilities)):
        print(f"\nDurak {i+1}:")
        print(f"GÃ¼neÅŸlenme: {new_stops['irradiation_kWh'][i]} kWh/yÄ±l")
        print(f"Yolcu YoÄŸunluÄŸu: {new_stops['passenger_density'][i]}")
        print(f"Metro UzaklÄ±ÄŸÄ±: {new_stops['metro_distance'][i]} m")
        print(f"Tahmin: {'Uygun' if pred == 1 else 'Uygun DeÄŸil'}")
        print(f"Uygunluk OlasÄ±lÄ±ÄŸÄ±: {prob[1]:.2%}")

def main():
    # Verileri yÃ¼kle
    df = load_and_prepare_data()
    
    # Modeli eÄŸit
    model, scaler, features = train_model(df)
    
    # Modeli kaydet
    save_model(model, scaler, features)
    
    # Yeni duraklar iÃ§in tahmin yap
    predict_new_stops(model, scaler, features)

if __name__ == "__main__":
    main() 